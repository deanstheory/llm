{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e75463c-e34f-4d6a-a201-57bd404c00a0",
   "metadata": {},
   "source": [
    "# Prompt Templates\n",
    "\n",
    "A prompt template is a pre-defined structure that is used to generate prompts for large language models (LLMs). \n",
    "\n",
    "Benefits of using prompt templates:\n",
    "\n",
    "* **Improved quality**: Prompt templates can help to improve the quality of prompts by providing a structure and a set of instructions that the LLM can follow.\n",
    "* **Consistency**: Prompt templates can help to ensure that prompts are consistent, which can lead to more consistent results.\n",
    "* **Reduced time**: Prompt templates can help to reduce the time it takes to generate prompts by providing a pre-defined structure that can be used to quickly generate prompts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a5a633-17dc-4bfb-9f01-cd26b741a399",
   "metadata": {},
   "source": [
    "----\n",
    "## Environment set up\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d554e7c4-39f3-45d8-9abe-ac71a792ac9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install langchain --upgrade\n",
    "!pip install openai --upgrade\n",
    "!pip install pypdf --upgrade\n",
    "!pip install chromadb --upgrade\n",
    "!pip install pinecone-client --upgrade\n",
    "!pip install ipywidgets --upgrade\n",
    "!pip install tiktoken --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d32af03-54de-4666-bb08-119d8b2f78dd",
   "metadata": {
    "hide_input": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check to see if there is an environment variable with your API keys, if not, use what you put below\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY', 'YourAPIKey')\n",
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY', 'YourAPIKey')\n",
    "PINECONE_API_ENV = os.environ.get('PINECONE_API_ENV', 'us-west4-gcp') # You may need to switch with your env\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ab12c7-e994-4365-8db9-9942ef4d041c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a0736d6-a944-4550-87d9-395601699617",
   "metadata": {
    "tags": []
   },
   "source": [
    "-----\n",
    "# Prompt templates\n",
    "\n",
    "<img src=\"./data/prompt_template.png\">\n",
    "\n",
    "* [Retrieval Question/Answering](https://python.langchain.com/en/latest/modules/chains/index_examples/vector_db_qa.html)\n",
    "\n",
    "https://towardsdatascience.com/a-gentle-intro-to-chaining-llms-agents-and-utils-via-langchain-16cd385fca81\n",
    "\n",
    "\n",
    "\n",
    "References:\n",
    "* https://www.pinecone.io/learn/langchain-prompt-templates/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabe0a1d-e292-4184-969e-4d43e5e485ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. The answer should be in form of bullet points (2 points minimum). If you don't know the answer, just say that you don't know, don't try to make up an answer. The answer should be in English.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267f24ab-19a4-49dd-9dbb-c703583c8c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "PROMPT.format(\n",
    "        context=\"You are a customer support representative responding to airline passengers\",\n",
    "        question=\"What day is it?\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549b2dab-c942-416f-83d1-87d8730b0b7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(temperature=0), \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=chroma_store.as_retriever(search_kwargs={'k':3}), \n",
    "    chain_type_kwargs=chain_type_kwargs, \n",
    "    return_source_documents=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "query = \"Can I get hotel accomodation if my flight is cancelled?\"\n",
    "context = \"You are a customer support representative responding to airline passengers\"\n",
    "\n",
    "answer = qa({\"query\": query, \"context\": context})\n",
    "print(answer['result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0209af91-763e-4fb6-bcaa-f02516b67990",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e469bb96-707a-42bc-a435-4b1afe23f3cb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Few shot prompt templates\n",
    "\n",
    "https://python.langchain.com/en/latest/modules/prompts/prompt_templates/examples/few_shot_examples.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d15d515-1174-40b8-8772-9788b541a8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
